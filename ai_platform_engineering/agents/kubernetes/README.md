# üöÄ Kubernetes AI Agent

[![Python](https://img.shields.io/badge/python-3.13%2B-blue?logo=python)](https://www.python.org/)
[![Poetry](https://img.shields.io/badge/poetry-2.1.1%2B-blueviolet?logo=python)](https://python-poetry.org/)
[![License](https://img.shields.io/badge/license-Apache%202.0-green)](LICENSE)

[![Conventional Commits](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/conventional_commits.yml/badge.svg)](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/conventional_commits.yml)
[![Ruff Linter](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/ruff.yml/badge.svg)](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/ruff.yml)
[![Super Linter](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/superlinter.yml/badge.svg)](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/superlinter.yml)
[![Unit Tests](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/unit-tests.yml)

[![A2A Docker Build and Push](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/a2a-docker-build.yml/badge.svg)](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/a2a-docker-build.yml)
---

## üß™ Evaluation Badges

| Claude | Gemini | OpenAI | Llama |
|--------|--------|--------|-------|
| [![Claude Evals](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/claude-evals.yml/badge.svg)](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/claude-evals.yml) | [![Gemini Evals](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/gemini-evals.yml/badge.svg)](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/gemini-evals.yml) | [![OpenAI Evals](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/openai-evals.yml/badge.svg)](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/openai-evals.yml) | [![Llama Evals](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/openai-evals.yml/badge.svg)](https://github.com/cnoe-io/agent-kubernetes/actions/workflows/openai-evals.yml) |

---

- ü§ñ **Kubernetes Agent** is an LLM-powered agent built using the [LangGraph ReAct Agent](https://langchain-ai.github.io/langgraph/agents/agents/) workflow and [MCP tools](https://modelcontextprotocol.io/introduction).
- üåê **Protocol Support:** Compatible with [A2A](https://github.com/google/A2A) protocol for integration with external user clients.
- üõ°Ô∏è **Secure by Design:** Enforces Kubernetes API token-based authentication and supports external authentication for strong access control.
- üîå **Integrated Communication:** Uses [langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters) to connect with the Kubernetes MCP server within the LangGraph ReAct Agent workflow.
- üè≠ **First-Party MCP Server:** The MCP server is generated by our first-party [openapi-mcp-codegen](https://github.com/cnoe-io/openapi-mcp-codegen/tree/main) utility, ensuring version/API compatibility and software supply chain integrity.

---

## üèóÔ∏è Architecture

```mermaid
flowchart TD
  subgraph Client Layer
    A[User Client A2A]
  end

  subgraph Agent Transport Layer
    B[Google A2A]
  end

  subgraph Agent Graph Layer
    C[LangGraph ReAct Agent]
  end

  subgraph Tools/MCP Layer
    D[LangGraph MCP Adapter]
    E[Kubernetes MCP Server]
    F[Kubernetes API Server]
  end

  A --> B --> C
  C --> D
  D -.-> C
  D --> E --> F --> E
```

## ‚ú® Features

- ü§ñ **LangGraph + LangChain MCP Adapter** for agent orchestration
- üß† **Azure OpenAI GPT-4** as the LLM backend
- üîó Connects to Kubernetes via a dedicated Kubernetes MCP server
- üìä **Comprehensive Kubernetes API Support:**
  - Pod Management
  - Deployment Management
  - Service Management
  - ConfigMap/Secret Management
  - Namespace Operations
  - Cluster Status Monitoring
  - Resource Troubleshooting

---

## üöÄ Getting Started

### 1Ô∏è‚É£ Configure Environment

#### Setting Up Azure OpenAI

1. Go to [Azure Portal](https://portal.azure.com)
2. Create or select your Azure OpenAI resource
3. Navigate to "Keys and Endpoint" section
4. Copy the endpoint URL and one of the keys
5. In Azure OpenAI Studio:
   - Create a deployment for GPT-4
   - Note down the deployment name
   - You'll need these values for your `.env` file:
     - `AZURE_OPENAI_API_KEY`
     - `AZURE_OPENAI_ENDPOINT`
     - `AZURE_OPENAI_DEPLOYMENT`

#### Setting Up Kubernetes Configuration

1. Ensure you have `kubectl` installed and configured
2. Set up your kubeconfig file with cluster access
3. You'll need these values for your `.env` file:
   - `KUBE_CONFIG_PATH` - Path to your kubeconfig file (default: ~/.kube/config)

#### Port Configuration

- Default ports:
  - A2A Agent: 8000
  - MCP Server: 9000
- If port 8000 is already in use:
  1. Choose an available port (e.g., 8001, 8002, etc.)
  2. You'll need to update this in both:
     - Your `.env` file as `A2A_AGENT_PORT`
     - Your Docker run command port mapping

Now, create a `.env` file in the root directory with the following configuration:

```env
############################
# Agent Configuration
############################
LLM_PROVIDER=azure-openai
AGENT_NAME=github

## A2A Agent Configuration
A2A_AGENT_HOST=localhost
A2A_AGENT_PORT=8000  # Change this if port 8000 is already in use

## MCP Server Configuration
MCP_HOST=localhost
MCP_PORT=9000

############################
# Azure OpenAI Configuration
############################
# Get these values from your Azure OpenAI resource in Azure Portal
AZURE_OPENAI_API_KEY=<your-azure-key>  # Found in Azure Portal under "Keys and Endpoint"
AZURE_OPENAI_API_VERSION=2025-04-01-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4.1  # Your deployment name in Azure OpenAI
AZURE_OPENAI_ENDPOINT=<your-azure-endpoint>  # Found in Azure Portal under "Keys and Endpoint"

############################
# Google Gemini (if needed)
############################

GOOGLE_API_KEY=<your-google-api-key>

############################
# Kubernetes Configuration
############################
# Your Kubernetes Classic Token with the permissions listed above
GITHUB_PERSONAL_ACCESS_TOKEN=<your-github-token>
```

### 2Ô∏è‚É£ Start the Agent (A2A Mode)

1. Pull the A2A image:

```bash
docker pull ghcr.io/cnoe-io/agent-kubernetes:a2a-stable
```

2. Run the agent in a Docker container using your `.env` file:

```bash
docker run -it --rm \
  --env-file .env \
  -p 8000:8000 \
  -v /var/run/docker.sock:/var/run/docker.sock \
  ghcr.io/cnoe-io/agent-kubernetes:a2a-stable
```

### 3Ô∏è‚É£ Run the Client

First, set up a virtual environment and install required tools:

#### Set Up Virtual Environment

**For Linux/macOS:**

```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
source .venv/bin/activate
```

**For Windows:**

```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
. .venv\Scripts\activate
```

#### Install uv

```bash
# Install uv package manager
pip install uv
```

Now you can use the [agent-chat-cli](https://github.com/cnoe-io/agent-chat-cli) to interact with the agent:

```bash
uvx https://github.com/cnoe-io/agent-chat-cli.git a2a
```

## Local Development

### Alternative: Running Locally
You can also run the agent locally without Docker:

First clone the repo:

```bash
git clone https://github.com/cnoe-io/agent-kubernetes.git
cd agent-kubernetes
```

```bash
make run-a2a
```

In a new terminal, start the A2A client:

```bash
make run-a2a-client
```

## Quick Demos

### ‚ñ∂Ô∏è Test with Kubernetes API

#### üèÉ Quick Start: Set Up Kubernetes Access

1. **Create a Kubernetes Account:**
   If you don't have one, sign up at [Kubernetes](https://github.com/).

2. **Generate a Personal Access Token:**
   - Go to Settings ‚Üí Developer settings ‚Üí Personal access tokens
   - Generate a new token with appropriate permissions
   - Save the token securely

3. **Configure Your Token:**
   - Add your token to the `.env` file as `GITHUB_PERSONAL_ACCESS_TOKEN`

### Example Interactions

1. **Repository Management**
```
User: list my repositories
Agent: Here are your Kubernetes repositories:

1. agent-kubernetes (Public)
   - Language: Python
   - Description: LLM-powered Kubernetes agent
   - Last updated: 2 days ago

2. agent-chat-cli (Public)
   - Language: Python
   - Description: CLI client for agent interaction
   - Last updated: 1 week ago

Let me know if you need more details about any repository!
```

2. **Issue Management**
```
User: create an issue in agent-kubernetes
Agent: Issue created successfully!

Title: Add new feature
Repository: agent-kubernetes
Issue #: 42
URL: https://github.com/yourusername/agent-kubernetes/issues/42

Would you like me to add any labels or assign someone to this issue?
```

## üîç Troubleshooting

### Common Issues

1. **Docker Issues**
   - Ensure Docker daemon is running
   - Check if you have sufficient permissions
   - Verify the required images are available

2. **Port Conflicts**
   - If port 8000 is in use, modify the port in `.env`
   - Check for other services using required ports

3. **Environment Variables**
   - Verify all required variables in `.env`
   - Check API keys and tokens are valid
   - No trailing spaces in values

4. **Client Connection Issues**
   - Server must be running before client
   - Port numbers should match
   - API keys must match between server and client

## Contributing

Please read our [Contributing Guide](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

## License

This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.
