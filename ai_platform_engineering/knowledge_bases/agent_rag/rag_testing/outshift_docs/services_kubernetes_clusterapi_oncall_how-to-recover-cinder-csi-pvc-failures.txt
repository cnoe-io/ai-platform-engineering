How-to: Recover Cinder CSI PVC failures when fluentd pod in pending state
¶
Tags:
"Fluentd PVC is failing"
Symptoms
¶
Fluentd pod in P3 k8s cluster is in pending state
Fluentd is filling up local buffers
Fluentd PVC is failing
Possible Alerts:
â ï¸ Incident
#5974
p3-prod-2: FluentdQueueLength: was triggered by the Prometheus service and assigned to Dev Null.
â ï¸ Incident
#5956
p3-prod-2: NodeFilesystemSpaceFillingUp:
 was triggered by the Prometheus service and assigned to Dev Null.
â ï¸ Incident
#5959
p3-prod-2: KubePodNotReady:
 was triggered by the Prometheus service and assigned to Dev Null.
Example error messages from fluentd:
Events:
Type     Reason            Age   From               Message
----     ------            ----  ----               -------
Warning  FailedScheduling  14s   default-scheduler  0/6 nodes are available: 6 pod has unbound immediate PersistentVolumeClaims.
Warning  FailedScheduling  14s   default-scheduler  0/6 nodes are available: 6 pod has unbound immediate PersistentVolumeClaims.
â¸ p3-prod-2-admin@p3-prod-2 in workspace/clusterapi/p3-prod-1 on âï¸  (us-east-2)
â¯ k get pvc -A
NAMESPACE        NAME                                       STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS           AGE
one-eye-system   data-p3-prod-2-one-eye-postgresql-0        Bound     pvc-8cad21ed-58b8-4721-b886-2a0c5f748d2f   8Gi        RWO            csi-cinder-sc-delete   46h
one-eye-system   one-eye-fluentd-buffer-one-eye-fluentd-0   Pending                                                                        csi-cinder-sc-delete   46h
Warning  ProvisioningFailed    84s (x8 over 2m27s)  cinder.csi.openstack.org_openstack-cinder-csi-controllerplugin-0_246ecc23-8235-48fc-97c9-9ea7500f7fca  failed to provision volume with StorageClass "csi-cinder-sc-delete": rpc error: code = Internal desc = CreateVolume failed with error Bad request with: [POST https://cloud-alln-1.cisco.com:8776/v3/647edac0922c41f1913c062d1f8a685c/volumes], error message: {"badRequest": {"message": "Availability zone 'cloud-alln-1-b' is invalid.", "code": 400}}
Normal   ExternalProvisioning  7s (x11 over 2m27s)  persistentvolume-controller                                                                            waiting for a volume to be created, either by external provisioner "cinder.csi.openstack.org" or manually created by system administrator
Resolution
¶
Verify label on all nodes
¶
Ensure your kubectl context is set to the source kubernetes cluster that is being triaged
If any pod in the openstack-cinder-csi namespace is in a pending or showing ⅔ running, then it is be necessary to first reset the associated nodes to their proper zone and then flip them to nova once the pod is running 3/3.  The first line below (in labels when you edit the node), if it says nova, needs to be set to the same value as the third line.  Once you change the label, either wait for the pod to recover or delete the pod and it will start running 3/3, then proceed with the next step.
topology.cinder.csi.openstack.org/zone: cloud-alln-1-a
topology.kubernetes.io/region: cloud-alln-1
topology.kubernetes.io/zone: cloud-alln-1-a
Once all the pods are in running state, now ensure each node in P3 cluster has this label
topology.cinder.csi.openstack.org/zone: nova
for node in $(kubectl get nodes -o name);
do
kubectl label nodes --overwrite=true "${node##*/}" topology.cinder.csi.openstack.org/zone=nova;
done
Verify if PVC creation is successful after this step
Re-create logging resources to re-trigger a new PVC
¶
If the above step doesn't work, please do the following
Delete the PVC attached to the fluend
If PVC/PV/Pod are stuck in "Terminating" state. Remove
- kubernetes.io/pv-protection
from the finalizer
kubectl patch pvc <pvc_name> -p '{"metadata":{"finalizers":null}}'
kubectl patch pv <pv_name> -p '{"metadata":{"finalizers":null}}'
kubectl patch pod <pod_name> -p '{"metadata":{"finalizers":null}}'
Delete the loggings.logging.banzaicloud.io resource
This removes fluentbit/fluentd from the cluster.
Sync MCOM from ArgoCD and watch for
loggings.logging.banzaicloud.io
.
2022-10-20