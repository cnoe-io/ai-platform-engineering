Code nad Build
SCS
post mortem
scb-scanner
2024-02-26; Scb scanner jobs runs on default nodegroup and used all possible resources that did not allowed to other services feeling comfortable
¶
Summary
¶
Scb scanner has CRD scan that creates pods per github repository scan, it was scheduled to run on default node group and not on karpente, the amount of pods were about 13K
When
¶
2024-02-26 11:00 IST - 2024-02-26 15:00 IST
Timeline
¶
2024-02-26
11:00 IST - Got alert from posture-security-findings team that their pods on pending state
11:30 IST - Ralized that that scb-scanners seating on the same nodegroup and has 13K pods in queue
12:00 IST - Tried to delete scb-scanners with alon, but no luck, scaners are deployed by some crd scan and some controller, its job that creates pod
12:30 IST - Added more nodes to default group that directly were taken by scanners, Alon cleaned SQS queue, but pods still were online
13:00 IST - Added nodepool on karpenter for scb-scanners only
13:30 IST - Added kyverno and kyverno policies that added nodeselectors and tolerations to posture-security-findings namespace in terms of let them to work till we fix scb-scanners
14:00 IST - Added kyverno cluster policy for scb-scanners namespace , but not all pods were patched and rescheduled.
14:30 IST - Excluded from argocd whole scb deployment that was removed after by argo
15:00 IST - Once argo removed all resources from scb namespace, pods and jobs were still alive
15:30 IST - After some time they have removed.
16:00 IST - Added scb deployment back that was rescheduled on karpenter special node pool that runs on SPOT
Impact
¶
System(s) impacted?
¶
Code and Build
Teams impacted?
¶
Code and Build
Analysis
¶
We have added scans to separate nodepool and isolated it from other workloads
Scans alocate enoumourous amount of resources
Takeaways
¶
- Moved scaners out to separate nodepool
- Aligned all setups and stages
2024-02-28