INC240529 2024-05-28-P3-Prod-2-deletion
¶
When
¶
2024-05-28 afternoon - 2024-05-31 morning
Summary
¶
The
P3-Prod-2
CAPI (Cluster API) managed cluster was accidentally deleted by the SRE team. This was due to some UI mishaps when trying to delete a different cluster that was not in use and was planned for removal
p3-capi-control-1
. While deleting the resources in the
p3-capi-control-1
project via the UI, the projects got switched mid process and it started deleting the
P3-Prod-2
cluster as well. Unfortunately, we were unable to cancel the deletion process in time. SRE team tried reconciling the cluster but it was not successful. The cluster was then recreated from scratch using micro k8s and the applications were redeployed using the DB backups from the volumes that were still up and running.
Timeline
¶
2024-05-28
¶
12:00 IST: Continuing the process of P# generic user rotation and removing old P3 Capi clusters that were no longer in use
12:10 IST: While trying to remove left over resources via the UI for the
p3-capi-control-1
project, the projects got switched and the
P3-Prod-2
cluster was deleted in addition to the
p3-capi-control-1
cluster resources.
12:15 IST: Tried to cancel/reconcile via the UI but the process was already in progress and could not be stopped.
12:22 IST: Message was sent tot he Outshift Platform Status space to notify the team of the accidental deletion of the
P3-Prod-2
cluster.
12:35 IST: Investigated/discovered exactly which resources were deleted and which were still up and running. Notified the team of the findings and clarified that the DB volumes were still up and running.
12:45 IST: Tried to reconcile the cluster by running the Terraform I found in our SRE-TF-Infra repo:
https://wwwin-github.cisco.com/eti/sre-tf-infra/tree/dbaf782591cc1dc3ad6ca70eda2a3d71707bb355/p3/capo/cloud-rcdn-1/p3-prod-2
12:57 IST: The reconciliation process was seemed to be successful and the team was notified. -
https://wwwin-github.cisco.com/eti/sre-tf-infra/pull/1231
13:00 IST: After further investigation, it was found that the reconciliation process was not successful and the cluster was not accessible. The UI showed that it was up and running, but no one was able to access it to make sure that we could re-deploy the applications + recover the data from the volumes.
17:30 IST: After multiple tried to make a fix in-place for the cluster, it was decided to recreate the cluster from scratch using the existing CAPI Controller and Terraform.
19:30 IST: Multiple tries to deploy the cluster from scratch were unsuccessful. It kept getting stuck on the load balancer creation and the cluster was not accessible by the control plane.
2024-05-29
¶
10:50 IST: An incident was created via the Incident Command Bot to track all the issues and findings:
https://cisco-eti.atlassian.net/browse/INC-13
11:05 IST: After multiple tries to reconcile the cluster using the CAPI controller, it was decided to recreate the cluster using micro k8s in a P3 environment.
11:10 IST: The new micro k8s cluster was operational, and the team started setting up the base apps stack together with any required configurations.
13:09 IST: The base apps stack was deployed, but faced some discrepancies in some of the applications like external secrets and NGINX Ingress Controller/NLB.
17:00-19:00 IST: There were issues with setting up the P3 load balancer to work with the new micro k8s cluster. The team tried multiple configurations and settings but was unable to get the load balancer to work correctly. It was decided that we would deploy our own
metalLB
to workaround this issue.
22:05 IST: After conversing with the Openstack teams, it was made apparent that the root cause of the issue was the Load Balancers features in P3, which were not operational because of a bug they have found and put forth to Redhat. This bug was across all the P3 environment stacks and effected everyone. The team mentioned that they were having difficulties getting a response from Redhat and that the issue was not going to be resolved in the near future.
2024-05-30
¶
12:05 IST: The team decided to deploy
metalLB
to the micro k8s cluster to workaround the issue with the P3 Load Balancers. This proved to be successful and the team was able to get the applications up and running.
19:00 IST: The team notified that they were able to get all the baseapps operational as expected as well as all the SRE related applications configured and running. There was only the matter of recovering the data from the DB backups and setting them up with the application deployments for Data-Dashboards.
19:10 IST: The team synced up between multiple members to make sure that the data-dashboards deployments were operational and that they could begin setting up the data from the DB backups.
19:13 IST: Teams were notified that all the applications, that did not require the DB restoration process, were up and running as expected.
2024-05-31
¶
05:16 IST: The team notified all customers that all the applications were now successfully reconciled and operational after the data restoration process for both Dev and Prod environments.
Impact
¶
System(s) impacted?
¶
Data-Dashboards (Partially/Internal instance)
Teams impacted?
¶
Websites/PLG/Data-Dashboards
Analysis
¶
Accidental deletion of the resources by a discrepency in the UI console together with human error, caused a crucial internal resource to go down. Multiple recovery procedures did not help in order to reconcile the cluster and the team had to recreate the cluster from scratch. The team was able to recover the data from the DB backups and set up the applications as expected. The root cause of the issue was found to be a bug in the P3 Load Balancer features, which were not operational across all the P3 environments. The team was able to workaround this issue by deploying
metalLB
to a new micro k8s cluster in a P3 instance.
Takeaways
¶
Using the UI console should be done with extreme caution and double checking the resources that are being deleted.
Openstack + Cluster API can be extremely complex to debug/use without the necessary expertise and knowledge within the team; which we currently do not have enough of unfortunately.
microk8s
is a great tool for testing and deploying small k8s clusters, but it is not a replacement for a full fledged k8s cluster. It is very easy to setup and manage, and is a good enough solution for now to handle these small sized applications and configurations for the internal integrations.
We will need to find a better way, with time, of how to handle our internal resources via P3 and the Openstack environments. The current setup is not sustainable and is causing a lot of issues for the team and the applications that are being deployed.
We need to have a better way of handling the data backups and restoration process for the applications that are being deployed. This process is currently manual and is not sustainable for the long term. We need to find a way to automate this process and make it more reliable for the team to use in the future.
We need to have better communication with the Openstack/P3 teams to make sure that we are aware of any issues that are happening in the environment and that we can work together to resolve them in a timely manner. The current communication process is not working and we are left unaware of the issues that are happening in the environment until it is too late.
2024-06-30