Delete EKS Cluster
¶
Delete EKS Cluster
How to
Delete an EKS Cluster (eti-infra)
Delete an EKS Cluster (sre-tf-infra)
Troubleshooting
aws_auth: unauthorized
VPC errors
Workaround
Context
Investigation
References
How to
¶
Delete an EKS Cluster (eti-infra)
¶
You will need to create
two
separate PRs: one to delete the EKS cluster, and another to delete the EKS cluster's
network
components.
Drain the EKS cluster nodes
While waiting for the cluster to drain, create a PR in
eti-infra
for executing the destroy command for the EKS cluster.
create and push an empty commit:
git commit --allow-empty -m "destroying <cluster-name>"
Delete the monitoring chart from the cluster to prevent unnecessary pages:
helm
delete
--purge
monitoring
Post the following comment in the eti-infra PR to run a
terraform plan
:
atlantis
plan
-p
<cluster-name>
Post the following comment in the eti-infra PR to run a
terraform destroy
(requires at least one PR approval):
atlantis
destroy
-p
<cluster-name>
Note:
The destroy process can take upwards of an hour.
- After the destroy command completes, delete metadata for that cluster in the same PR:
- Remove the cluster from
manifest.yaml
- Remove the cluster from
atlantis.yaml
- Remove the
.tf
file in
clusters/<cluster_name>/main.tf
-
Merge the PR
-
Example PR for reference
Create another PR in
eti-infra
for executing the destroy command for
<cluster-name>-network
.
create and push an empty commit:
git commit --allow-empty -m "destroying <cluster-name>-network"
Post the following comment in the eti-infra PR to run a
terraform plan
:
atlantis
plan
-p
<cluster-name>-network
Post the following comment in the eti-infra PR to run a
terraform destroy
(requires at least one PR approval):
atlantis
destroy
-p
<cluster-name>
After the destroy command completes, delete metadata for that cluster in the same PR:
Remove the
name: <cluster-name>
from the top-level
networks
map in
manifest.yaml
Remove the
<cluster-name>-network
from
atlantis.yaml
Remove the
infra_environments/networks/<cluster-name>
directory (including
main.tf
)
Remove the
name: <cluster-name>
block from
ip_allocations.yaml
Remove CIDR reservation for
<cluster-name>
in
IP_ALLOCATIONS.md
Merge the PR
Example PR for reference
Delete the cluster from
ArgoCD
Delete references to the cluster is
sre-cluster-configs
Delete ssh keys in
Keeper
. The keys should be under a folder with the same name as the EKS cluster.
Delete an EKS Cluster (sre-tf-infra)
¶
Ensure the cluster is unused.
Start a branch in
sre-tf-infra
create and push an empty commit:
git commit --allow-empty -m "destroying <cluster-name>-network"
Start a Pull Request.
In the comment of the PR, type
atlantis plan -p <project-name>
If the plan fails, you will probably need to delete the cluster manually.
After the plan runs successfully, type
atlantis plan -p <project-name> -- -destroy
.
A successful destroy will close the PR
Start another branch and PR as above.
Delete the references to the cluster:
Delete the terraform files from the appropriate folder.
Remove the cluster from
atlantis.yaml
Merge and close the PR and delete the branch.
Delete the cluster from
ArgoCD
Delete references to the cluster is
sre-cluster-configs
Delete ssh keys in
Keeper
. The keys should be under a folder with the same name as the EKS cluster.
Troubleshooting
¶
aws_auth: unauthorized
¶
remove aws_auth: unauthorizedâââââââ
Errors with
atlantis destroy -p <cluster-name>
Use
duo-ssoâââââââ
to authenticate against the aws for CLI access.
Navigate to
eti-infra/clusters/<cluster_name>
and run:
terraform
init
terraform
state
rm
'module.eks.module.eks.kubernetes_config_map.aws_auth[0]'
Run
atlantis destroy -p <cluster-name>
again
VPC errors
¶
VPC Errors with
atlantis destroy -p <cluster-name>-network
Workaround
¶
Follow the steps below to find the dependent resources not managed by terraform, then manually delete them before running
atlantis destroy -p <cluster>-network
:
Run the following commands (requires
jq
):
vpc
=
"vpc-xxxxxxxxxx"
# set this to your VPC ID
aws
elb
describe-load-balancers
|
\
jq
'.LoadBalancerDescriptions[] |
select(.VPCId == "'
$vpc
'") |
{LoadBalancerName: .LoadBalancerName, SecurityGroups: .SecurityGroups}'
Manually delete the detected loadbalancers and security groups via AWS Console:
"LoadBalancerName"
:
"a908acabeb5094ff2866938e964b6c0a"
,
"SecurityGroups"
:
[
"sg-0628f3a4a602b4331"
]
}
{
"LoadBalancerName"
:
"ac9efa5245b0a4817854fca2db5dce1d"
,
"SecurityGroups"
:
[
"sg-06b8a159337c844cd"
]
}
Try running
atlantis plan -p <cluster>-network
then
atlantis destroy -p <cluster>-network
again. If you still run into an error (e.g.,
Error waiting for internet gateway (igw-0ee6d31bb042f1620) to detach: couldn't find resource (31 retries)
), delete the VPC manually via AWS console. The console will show resources that must be deleted first. Run the
vpc_dependencies.sh
script to make sure that you find and delete all associated subnets, routetables, network acls, security groups, etc. Deleting the VPC via console will automatically delete most/all of these components; running this script is just a confirmation step.
Context
¶
SRE-1198
EKS cluster network components created via
eti-infra
fails deletion via terraform due to dependencies on resources, resulting in time-out error:
Error:
error
deleting
subnet
(
subnet-0d9c1211af5160cbe
)
:
timeout
while
waiting
for
state
to
become
'destroyed'
(
last
state:
'pending'
,
timeout:
20m0s
)
Error:
error
deleting
subnet
(
subnet-00f83b962f0fbe8bf
)
:
timeout
while
waiting
for
state
to
become
'destroyed'
(
last
state:
'pending'
,
timeout:
20m0s
)
Error:
Error
waiting
for
internet
gateway
(
igw-0ee6d31bb042f1620
)
to
detach:
timeout
while
waiting
for
state
to
become
'detached'
(
last
state:
'detaching'
,
timeout:
15m0s
)
Error:
error
deleting
subnet
(
subnet-01ffbe685781d7e94
)
:
timeout
while
waiting
for
state
to
become
'destroyed'
(
last
state:
'pending'
,
timeout:
20m0s
)
Error:
error
deleting
subnet
(
subnet-0da31da3f91f80016
)
:
timeout
while
waiting
for
state
to
become
'destroyed'
(
last
state:
'pending'
,
timeout:
20m0s
)
Error:
error
deleting
subnet
(
subnet-099b244d4f0128925
)
:
timeout
while
waiting
for
state
to
become
'destroyed'
(
last
state:
'pending'
,
timeout:
20m0s
)
Error:
Error
deleting
VPC:
DependencyViolation:
The
vpc
'vpc-0d67f8be25c814b45'
has
dependencies
and
cannot
be
deleted.
status
code:
400
,
request
id:
f944384d-6085-4f3b-ad67-70fca7fd4285
Investigation
¶
EKS creates additional resources (in this case, load balancers) as part of deploying services onto the cluster. Since these resources created by EKS/k8s are not managed by terraform, it cannot destroy them; however, AWS requires VPC dependencies to be terminated before the VPC itself can be terminated.
This seems to be a
common/known issue
that requires manually deleting the k8s-created resources, although this did not fix the entire problem.
Even after manually deleting the k8s-created loadbalancers and security groups,
atlantis destroy -p eks-stoader-1-network
failed again, this time with a different error:
Error:
Error
waiting
for
internet
gateway
(
igw-0ee6d31bb042f1620
)
to
detach:
couldn
'
t
find
resource
(
31
retries
)
I was not able to determine why terraform was unable to detect this internet gateway resource;
igw-0ee6d31bb042f1620
gateway existed in AWS and was attached to the
vpc-0d67f8be25c814b45
VPC. Finally, I tried running
atlantis apply -p eks-stoader-1-network
. This recreated
all
the network components, including a new, duplicate
eks-stoader-1
(
vpc-0284c00ac17143bbf
) VPC. A subsequent
atlantis destroy -p eks-stoader-1-network
successfully destroyed
all those network components (including the new internet gateway).
I went back and manually deleted the old, orphaned
eks-stoader-1
VPC and its related components via the AWS console. I confirmed that
vpc_dependencies.sh
script no longer detected any dependent resources for
vpc-0d67f8be25c814b45
.
References
¶
Stackoverflow Answer 1
- k8s deployment creates LBs unmanaged by terraform
Stackoverflow Answer 2
- seems like our issue
AWS Support Page
- script to detect VPC dependencies
terraform bug
- we're not alone
terraform-aws-vpc
issue
2023-10-26