# Copyright 2025 CNOE Contributors
# SPDX-License-Identifier: Apache-2.0

import logging
import uuid
import os
from langchain_core.messages import AIMessage
from langgraph.graph.state import CompiledStateGraph
from langgraph_supervisor import create_supervisor
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.memory import InMemoryStore
from cnoe_agent_utils import LLMFactory

# Conditional langfuse import based on ENABLE_TRACING
if os.getenv("ENABLE_TRACING", "false").lower() == "true":
    from langfuse import observe
else:
    # No-op decorator when tracing is disabled
    def observe(**kwargs):
        def decorator(func):
            return func
        return decorator

from ai_platform_engineering.multi_agents.platform_engineer.prompts import (
  system_prompt,
  response_format_instruction
)

from ai_platform_engineering.agents.argocd.a2a_agent_client.agent import argocd_agent
from ai_platform_engineering.agents.atlassian.agent import atlassian_agent
from ai_platform_engineering.agents.pagerduty.agent import pagerduty_agent
from ai_platform_engineering.agents.github.agent import github_agent
from ai_platform_engineering.agents.slack.agent import slack_agent
from ai_platform_engineering.agents.backstage.agent import backstage_agent
import os

from ai_platform_engineering.utils.models.generic_agent import (
  ResponseFormat
)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AIPlatformEngineerMAS:
  def __init__(self):
    self.graph = self.build_graph()

  def get_graph(self) -> CompiledStateGraph:
    """
    Returns the compiled LangGraph instance for the AI Platform Engineer MAS.

    This method initializes the graph if it has not been created yet and returns
    the compiled graph instance.

    Returns:
        CompiledStateGraph: The compiled LangGraph instance.
    """
    if not hasattr(self, 'graph'):
      self.graph = self.build_graph()
    return self.graph

  def build_graph(self) -> CompiledStateGraph:
    """
    Constructs and compiles a LangGraph instance.

    This function initializes a `SupervisorAgent` to create the base graph structure
    and uses an `InMemorySaver` as the checkpointer for the compilation process.

    The resulting compiled graph can be used to execute Supervisor workflow in LangGraph Studio.

    Returns:
    CompiledGraph: A fully compiled LangGraph instance ready for execution.
    """
    model = LLMFactory().get_llm()

    # Check if LANGGRAPH_DEV is defined in the environment
    if os.getenv("LANGGRAPH_DEV"):
      checkpointer = None
      store = None
    else:
      checkpointer = InMemorySaver()
      store = InMemoryStore()

    graph = create_supervisor(
      model=model,
      agents=[
        argocd_agent,
        atlassian_agent,
        pagerduty_agent,
        github_agent,
        slack_agent,
        backstage_agent,
        # Add other agents here as needed
      ],
      prompt=system_prompt,
      add_handoff_back_messages=False,
      output_mode="last_message",
      response_format=(response_format_instruction, ResponseFormat),
    ).compile(
      checkpointer=checkpointer,
      store=store,
    )
    logger.debug("LangGraph supervisor created and compiled successfully.")
    return graph

  @observe(name="Supervisor Agent - Process Request")
  async def serve(self, prompt: str):
    """
    Processes the input prompt and returns a response from the graph.
    Args:
        prompt (str): The input prompt to be processed by the graph.
    Returns:
        str: The response generated by the graph based on the input prompt.
    """
    try:
      logger.debug(f"Received prompt: {prompt}")
      if not isinstance(prompt, str) or not prompt.strip():
        raise ValueError("Prompt must be a non-empty string.")
      result = await self.graph.ainvoke({
          "messages": [
              {
                  "role": "user",
                  "content": prompt
              }
          ],
      }, {"configurable": {"thread_id": uuid.uuid4()}})

      messages = result.get("messages", [])
      if not messages:
        raise RuntimeError("No messages found in the graph response.")

      # Find the last AIMessage with non-empty content
      for message in reversed(messages):
        if isinstance(message, AIMessage) and message.content.strip():
          logger.debug(f"Valid AIMessage found: {message.content.strip()}")
          return message.content.strip()

      raise RuntimeError("No valid AIMessage found in the graph response.")
    except ValueError as ve:
      logger.error(f"ValueError in serve method: {ve}")
      raise ValueError(str(ve))
    except Exception as e:
      logger.error(f"Error in serve method: {e}")
      raise Exception(str(e))
